{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Supervised Learning - Text Classification</center>\n",
    "References:\n",
    "* http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Finally, we come to machine learning ...\n",
    "What can the players do when their every move is studied and predicted ?\n",
    "\n",
    "<img src=\"machine_learning_cartoon.png\" width=\"60%\">\n",
    "https://www.kdnuggets.com/2018/06/cartoon-fifa-world-cup-football-machine-learning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Review basic concepts of machine learning\n",
    "  * Cross validation\n",
    "  * Performance metrics: recall and precision\n",
    "* Text Classification  \n",
    "  * Assign a document into one  or more pre-defined categories (or labels)\n",
    "    * Input: \n",
    "      - a document $d$ \n",
    "      - a fixed set of classes C = {$c_1$, $c_2$,..., $c_J$}\n",
    "      - A training set of $m$ hand-labeled documents ($d_1,c_1$),....,($d_m,c_m$)\n",
    "    * Output: a classifier that predicts $d$ to some classes $c$ $\\subset$ C\n",
    "  * **Single-label** classification: e.g. spam dection, sentiment detection\n",
    "  * **Multi-label** classification: e.g. news categorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Review basic concepts of machine learning\n",
    "### 2.1. Model assessment and selection - How valid is a model? \n",
    "- Generalization: the prediction capability of a model ($f$) on independent test data, \n",
    "  - Given testing samples ($X, Y$), and prediction ($X, f(X)$)\n",
    "  - Testing error: $L(Y, f(X))$, e.g.\n",
    "     - squared error\n",
    "     - absolute error\n",
    "  \n",
    "- Data-rich situation: split data into training, validation, and test sets (e.g. 50%, 25%, 25%)\n",
    "  - training set: fit the model\n",
    "  - validation set: estimate prediction error for model selection\n",
    "  - test set: assess the prediction erorr of the final chosen model\n",
    "  <img src=\"train_validation_test.png\" width=\"40%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Cross Validation\n",
    "- However, labeled data is always scarce. We cannot afford to set aside a validation set\n",
    "- $K$-fold cross validation: \n",
    "    - Data is separated into k subsets. Each time, one of the subsets is held as the test set (a.k.a holdout) and the rest of them is used as the training set. \n",
    "    <img src=\"cross_validation.png\" width=\"40%\"> [source] (http://spark-public.s3.amazonaws.com/nlp/slides/sentiment.pptx)\n",
    "    - This method repeats *k* times and each time with a different subset as the test set. \n",
    "    - Calculate average prediction error ($CV$) on K test sets $$ CV(\\alpha) = \\frac{1}{N} \\sum_{i=1}^{N}{L(y_i, f^{k(i)}(x_i, \\alpha))}$$ where $\\alpha$: the model parameters (e.g. the number of neighbours in $k$-NN), $f^{k(i)}$: the model fitted on the $k$th iteration, $N$: number of samples\n",
    "    - Tune model parameters ($\\alpha$) to minize the average prediction error\n",
    "    - Select the model with the minimal prediction error (along with $\\alpha$ determined)\n",
    "    - Fit the selected model to all the data\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Performance metrics\n",
    "  * Precision: precentage of true cases among the predicated true cases\n",
    "  * Recall:  precentage of true cases that have been retrieved over the total number of true cases\n",
    "  * F-score: $$\\frac{2*precision*recall}{precision+recall}$$\n",
    "  * Example: \n",
    "Confusion Matrix: <img src=\"confusion_matrix.png\">\n",
    "    * For \"YES\" group: \n",
    "      - precision=?, \n",
    "      - recall=?, \n",
    "      - f-score=?\n",
    "      <img src=\"precision_recall.png\" width=\"60%\">\n",
    "    * For \"NO\" group:\n",
    "      - precision=?, \n",
    "      - recall=?, \n",
    "      - f-score=?\n",
    "  * Overall model performance\n",
    "    * precision_macro (or recall_macro or f1_macro) is calculated as:\n",
    "      1. calculate precision for each label\n",
    "      2. average over labels \n",
    "    * precision_micro (or recall_micro or f1_micro): calculates metrics globally regardless of labels\n",
    "    * With inbalanced classes, the difference between these two metrics may be significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes : Pre: 100/(100+10), Rec: 100/(100+5) No : Pre: 50/(50+5), Rec: 50/(50+10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Basic process\n",
    "  1. Load and preprocess sample data\n",
    "  2. Extract features: e.g. bag of words with TF-IDF weights\n",
    "  3. Split feature space into trainning and test sets following cross validation method\n",
    "  4. Train a classifier/model with the training dataset using selected classification algorithm for each fold\n",
    "  5. Calculate performance\n",
    " \n",
    "* Considerations for deciding text classification algorithms\n",
    "  - should be effective in high dimensional spaces (**curse of dimensionality**)\n",
    "  - should be effective even if **the number of features is greater than the number of samples**\n",
    "    * Is regression a good alogorithm if you have a small number of text samples?\n",
    "  - some good algorithms to start with:\n",
    "      - Naive Bayes (https://web.stanford.edu/class/cs124/lec/naivebayes.pdf): baseline for performance benchmarking of text classification algorithms\n",
    "      - Support Vector Machine (SVM). References:\n",
    "        - https://www.svm-tutorial.com/2014/11/svm-understanding-math-part-1/\n",
    "        - http://www.robots.ox.ac.uk/~az/lectures/ml/lect2.pdf\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: sd345@city.ac.uk (Michael Collier)\\nSubj...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\...</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: djohnson@cs.ucsd.edu (Darin Johnson)\\nSu...</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: s0612596@let.rug.nl (M.M. Zwart)\\nSubjec...</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: stanly@grok11.columbiasc.ncr.com (stanly...</td>\n",
       "      <td>soc.religion.christian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   label\n",
       "0  From: sd345@city.ac.uk (Michael Collier)\\nSubj...           comp.graphics\n",
       "1  From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\...           comp.graphics\n",
       "2  From: djohnson@cs.ucsd.edu (Darin Johnson)\\nSu...  soc.religion.christian\n",
       "3  From: s0612596@let.rug.nl (M.M. Zwart)\\nSubjec...  soc.religion.christian\n",
       "4  From: stanly@grok11.columbiasc.ncr.com (stanly...  soc.religion.christian"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.1.: Load data \n",
    "# Load datasets (http://qwone.com/~jason/20Newsgroups/)\n",
    "# For convenience, a subset of the data has been saved into \"twenty_news_data.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "data=pd.read_csv(\"twenty_news_data.csv\",header=0)\n",
    "data.head()\n",
    "\n",
    "# print out the full text of the first sample\n",
    "print(data[\"text\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. TF-IDF matrix generation\n",
    "- Function: **sklearn.feature_extraction.text.TfidfVectorizer**(input='content',encoding='utf-8', decode_error='strict', token_pattern='(?u)\\b\\w\\w+\\b', lowercase=True, stop_words=None, ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, norm='l2', use_idf=True, smooth_idf=True, ...)\n",
    "- Some useful parameters:\n",
    "    * **input** : string {'filename', 'file', 'content').\n",
    "    * **encoding** : encoding scheme, 'utf-8' by default.\n",
    "If bytes or files are given to analyze, this encoding scheme is used to decode.\n",
    "    * **decode_error** : {'strict', 'ignore', 'replace'}: Instruction on what to do if a byte sequence is given to analyze that contains characters not of the given encoding. By default, it is 'strict', meaning that a UnicodeDecodeError will be raised. Other values are ‘ignore’ and ‘replace’.\n",
    "    * **token_pattern** : Regular expression denoting what constitutes a “token”. The default is '(?u)\\b\\w\\w+\\b', i.e. a token contains at least two word characters in unicode (note: ?u: unicode, \\b: space or non-word character, i.e. boundary, \\w: word character). \n",
    "    * **ngram_range** : tuple (min_n, max_n): The lower and upper boundary of the range of n-values for different n-grams to be extracted. \n",
    "    * **stop_words** : string {‘english’}, list, or None (default)\n",
    "    * **lowercase** : boolean, default True: Convert all characters to lowercase before tokenizing.\n",
    "    * **max_df/min_df** : float in range [0.0, 1.0] or int, default=1.0: When building the vocabulary ignore terms that have a document frequency strictly higher (lower) than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. \n",
    "    * **max_features** : int or None, default=None. If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus.\n",
    "    * **norm** : 'l1', 'l2' or None, optional. Norm used to normalize term vectors. None for no normalization.\n",
    "    * **use_idf** : boolean, default=True. Enable inverse-document-frequency reweighting.\n",
    "    * **smooth_idf** : boolean, default=True. Smooth idf weights by adding one to document frequencies, as if an extra document was seen containing every term in the collection exactly once. Prevents zero divisions.\n",
    "- For all the parameters, see http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of dtm: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "size of tfidf matrix: (2257, 35788)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.2 Create TF-IDF Matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# initialize the TfidfVectorizer \n",
    "\n",
    "tfidf_vect = TfidfVectorizer() \n",
    "\n",
    "# with stop words removed\n",
    "# tfidf_vect = TfidfVectorizer(stop_words=\"english\") \n",
    "\n",
    "# generate tfidf matrix\n",
    "dtm= tfidf_vect.fit_transform(data[\"text\"])\n",
    "\n",
    "print(\"type of dtm:\", type(dtm))\n",
    "print(\"size of tfidf matrix:\", dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of words: 35788\n",
      "type of vocabulary: <class 'dict'>\n",
      "index of word 'city' in vocabulary: 8696\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.3. Examine TF-IDF\n",
    "\n",
    "# 1. Check vocabulary\n",
    "\n",
    "# Vocabulary is a dictionary mapping a word to an index\n",
    "\n",
    "# the number of words in the vocabulary\n",
    "print(\"total number of words:\", len(tfidf_vect.vocabulary_))\n",
    "\n",
    "print(\"type of vocabulary:\", \\\n",
    "      type(tfidf_vect.vocabulary_))\n",
    "print(\"index of word 'city' in vocabulary:\", \\\n",
    "      tfidf_vect.vocabulary_['city'])\n",
    "#print(tfidf_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original text: \n",
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n",
      "\n",
      "tfidf weights: \n",
      "\n",
      "(35788,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('collier', 0.3841803935867984),\n",
       " ('city', 0.314400065528974),\n",
       " ('071', 0.25612026239119895),\n",
       " ('laserjet', 0.24645540709354397),\n",
       " ('477', 0.24645540709354397),\n",
       " ('converting', 0.21567205914741705),\n",
       " ('michael', 0.1962279892331408),\n",
       " ('iii', 0.18626015109199115),\n",
       " ('hp', 0.17358472047671197),\n",
       " ('files', 0.13635772403701527),\n",
       " ('sd345', 0.1348710554299733),\n",
       " ('8565', 0.1348710554299733),\n",
       " ('ec1v', 0.1348710554299733),\n",
       " ('x3769', 0.1348710554299733),\n",
       " ('0hb', 0.1348710554299733),\n",
       " ('tif', 0.12806013119559947),\n",
       " ('email', 0.125601499991304),\n",
       " ('ac', 0.12491817585060791),\n",
       " ('hpgl', 0.12322770354677198),\n",
       " ('img', 0.12322770354677198)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.4 check words with top tf-idf wights in a document, \n",
    "# e.g. 1st document\n",
    "\n",
    "# get mapping from word index to word\n",
    "# i.e. reversal mapping of tfidf_vect.vocabulary_\n",
    "voc_lookup={tfidf_vect.vocabulary_[word]:word \\\n",
    "            for word in tfidf_vect.vocabulary_}\n",
    "\n",
    "print(\"\\nOriginal text: \\n\"+data[\"text\"][0])\n",
    "\n",
    "print(\"\\ntfidf weights: \\n\")\n",
    "\n",
    "# first, covert the sparse matrix row to a dense array\n",
    "doc0=dtm[0].toarray()[0]\n",
    "print(doc0.shape)\n",
    "\n",
    "# get index of top 20 words\n",
    "top_words=(doc0.argsort())[::-1][0:20]\n",
    "[(voc_lookup[i], doc0[i]) for i in top_words]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "[0.9509893549239831]\n",
      "labels:  ['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n",
      "precision:  0.9570191644521808\n",
      "recall:  0.9509893549239831\n",
      "f-score:  0.9532387170094005\n",
      "support:  None\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       1.00      0.91      0.95       146\n",
      "         comp.graphics       0.95      0.98      0.97       172\n",
      "               sci.med       0.96      0.95      0.96       172\n",
      "soc.religion.christian       0.91      0.96      0.94       188\n",
      "\n",
      "           avg / total       0.95      0.95      0.95       678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.5. classification using a single fold\n",
    "\n",
    "# use MultinomialNB algorithm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# import method for split train/test data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import method to calculate metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# split dataset into train (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "                dtm, data[\"label\"], test_size=0.3, random_state=0)\n",
    "\n",
    "# train a multinomial naive Bayes model using the testing data\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "# predict the news group for the test dataset\n",
    "predicted=clf.predict(X_test)\n",
    "\n",
    "# get the list of unique labels\n",
    "labels=sorted(data[\"label\"].unique())\n",
    "# >>> np.unique([1, 1, 2, 2, 3, 3])\n",
    "# array([1, 2, 3])\n",
    "# >>> a = np.array([[1, 1], [2, 3]])\n",
    "# >>> np.unique(a)\n",
    "# array([1, 2, 3])\n",
    "\n",
    "# calculate performance metrics. \n",
    "# Support is the number of occurrences of each label\n",
    "\n",
    "precision, recall, fscore, support=\\\n",
    "     precision_recall_fscore_support(\\\n",
    "     y_test, predicted, labels=labels,average=\"macro\")\n",
    "print(type(recall))\n",
    "a=[]\n",
    "a.append(recall)\n",
    "print(a)\n",
    "print(\"labels: \", labels)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"f-score: \", fscore)\n",
    "print(\"support: \", support)\n",
    "\n",
    "# another way to get all performance metrics\n",
    "print(classification_report\\\n",
    "      (y_test, predicted, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 35788)\n",
      "0\n",
      "\n",
      " God is love\n",
      "alt.atheism: 0.171\n",
      "comp.graphics: 0.044\n",
      "sci.med: 0.053\n",
      "soc.religion.christian: 0.732\n",
      "'God is love' => soc.religion.christian\n",
      "1\n",
      "\n",
      " OpenGL on the GPU is fast\n",
      "alt.atheism: 0.174\n",
      "comp.graphics: 0.367\n",
      "sci.med: 0.234\n",
      "soc.religion.christian: 0.224\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n",
      "[[0.17055851 0.04441807 0.0530946  0.73192882]\n",
      " [0.17375257 0.36729648 0.2344663  0.22448465]]\n",
      "\n",
      "\n",
      "['soc.religion.christian' 'comp.graphics']\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.6.  predict new documents\n",
    "\n",
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "\n",
    "# generate tifid for new documents\n",
    "X_new_tfidf = tfidf_vect.transform(docs_new)\n",
    "\n",
    "print(X_new_tfidf.shape)\n",
    "\n",
    "# predict probability that each document belongs to a class\n",
    "predicted_p = clf.predict_proba(X_new_tfidf)\n",
    "\n",
    "# predict classes for new documents\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for idx, doc in enumerate(docs_new):\n",
    "    print(idx)\n",
    "    print('\\n', doc)\n",
    "    for j, label in enumerate(labels):\n",
    "        print('% s: %.3f'%(labels[j], predicted_p[idx][j]))\n",
    "    print('%r => %s' % (doc, predicted[idx]))\n",
    "    \n",
    "print(predicted_p)\n",
    "print('\\n')\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.7. Classification with stop words removed\n",
    "# Can removing stop words improves performance?\n",
    "# In Exercise 3.2, uncomment line 10 and comment line 7\n",
    "# Run Exercise 3.2, 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of dtm: <class 'scipy.sparse.csr.csr_matrix'>\n",
      "size of tfidf matrix: (2257, 35482)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.2 Create TF-IDF Matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# initialize the TfidfVectorizer \n",
    "\n",
    "tfidf_vect = TfidfVectorizer() \n",
    "\n",
    "# with stop words removed\n",
    "tfidf_vect = TfidfVectorizer(stop_words=\"english\") \n",
    "\n",
    "# generate tfidf matrix\n",
    "dtm= tfidf_vect.fit_transform(data[\"text\"])\n",
    "\n",
    "print(\"type of dtm:\", type(dtm))\n",
    "print(\"size of tfidf matrix:\", dtm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  ['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n",
      "precision:  [1.         0.9494382  0.96449704 0.91414141]\n",
      "recall:  [0.9109589  0.98255814 0.94767442 0.96276596]\n",
      "f-score:  [0.95340502 0.96571429 0.95601173 0.93782383]\n",
      "support:  [146 172 172 188]\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       1.00      0.91      0.95       146\n",
      "         comp.graphics       0.95      0.98      0.97       172\n",
      "               sci.med       0.96      0.95      0.96       172\n",
      "soc.religion.christian       0.91      0.96      0.94       188\n",
      "\n",
      "           avg / total       0.95      0.95      0.95       678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split dataset into train (70%) and test sets (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "                dtm, data[\"label\"], test_size=0.3, random_state=0)\n",
    "#print(X_train)\n",
    "#print(y_train)\n",
    "# train a multinomial naive Bayes model using the testing data\n",
    "clf = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "# predict the news group for the test dataset\n",
    "predicted=clf.predict(X_test)\n",
    "\n",
    "# get the list of unique labels\n",
    "labels=sorted(data[\"label\"].unique())\n",
    "# >>> np.unique([1, 1, 2, 2, 3, 3])\n",
    "# array([1, 2, 3])\n",
    "# >>> a = np.array([[1, 1], [2, 3]])\n",
    "# >>> np.unique(a)\n",
    "# array([1, 2, 3])\n",
    "\n",
    "# calculate performance metrics. \n",
    "# Support is the number of occurrences of each label\n",
    "\n",
    "precision, recall, fscore, support=\\\n",
    "     precision_recall_fscore_support(\\\n",
    "     y_test, predicted, labels=labels)\n",
    "\n",
    "print(\"labels: \", labels)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"f-score: \", fscore)\n",
    "print(\"support: \", support)\n",
    "\n",
    "# another way to get all performance metrics\n",
    "print(classification_report\\\n",
    "      (y_test, predicted, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data set average precision:\n",
      "[0.9644765  0.97075029 0.96607674 0.96636442 0.97161694]\n",
      "\n",
      "Test data set average recall:\n",
      "[0.95662898 0.96753147 0.96031162 0.9633648  0.97101794]\n",
      "\n",
      "Test data set average fscore:\n",
      "[0.959303   0.96880403 0.96227668 0.96460673 0.97118233]\n",
      "\n",
      "training data average f1:\n",
      " [0.99318413 0.99325989 0.99318465 0.99383792 0.99273675]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "K:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('train_f1_macro'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.8. Run 5-fold cross validation\n",
    "# to show the generalizability of the model\n",
    "\n",
    "# import cross validation method\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "metrics = ['precision_macro', 'recall_macro', \\\n",
    "           \"f1_macro\"]\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf = MultinomialNB(alpha=0.5)\n",
    "\n",
    "cv = cross_validate(clf, dtm, data[\"label\"], \\\n",
    "                    scoring=metrics, cv=5)\n",
    "print(\"Test data set average precision:\")\n",
    "print(cv['test_precision_macro'])\n",
    "print(\"\\nTest data set average recall:\")\n",
    "print(cv['test_recall_macro'])\n",
    "print(\"\\nTest data set average fscore:\")\n",
    "print(cv['test_f1_macro'])\n",
    "\n",
    "# To see the performance of training data set use \n",
    "# cv['train_xx_macro']\n",
    "print(\"\\ntraining data average f1:\\n\", cv['train_f1_macro'])\n",
    "\n",
    "# The metrics are quite stable across folds.\n",
    "# The performance between training and test sets is small\n",
    "# This indicates the model has good generalizability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.9. Multinominal NB \n",
    "# with different smoothing parameter alpha\n",
    "# comment line 11 and uncomment 12 in Exercise 3.8\n",
    "# use different alpha value to see if it affects performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data set average precision:\n",
      "[0.96819072 0.98266254 0.97026552 0.97103364 0.97654984]\n",
      "\n",
      "Test data set average recall:\n",
      "[0.9649264  0.98213231 0.96812323 0.96914739 0.97529176]\n",
      "\n",
      "Test data set average fscore:\n",
      "[0.96624991 0.98236882 0.96898206 0.96962624 0.97566628]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3.10. SVM model\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "#from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn import svm\n",
    "\n",
    "metrics = ['precision_macro', 'recall_macro', \"f1_macro\"]\n",
    "\n",
    "# initiate an linear SVM model\n",
    "clf = svm.LinearSVC()\n",
    "\n",
    "cv = cross_validate(clf, dtm, data[\"label\"], \\\n",
    "                    scoring=metrics, cv=5)\n",
    "print(\"Test data set average precision:\")\n",
    "print(cv['test_precision_macro'])\n",
    "print(\"\\nTest data set average recall:\")\n",
    "print(cv['test_recall_macro'])\n",
    "print(\"\\nTest data set average fscore:\")\n",
    "print(cv['test_f1_macro'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Parameter tuning using grid search\n",
    "* Each classification model has a few parameters\n",
    "  * e.g. \"stop_words\": \"english\" or None, min_df: [1,2,3, ...]\n",
    "  * e.g. MultinomialNB(alpha=1.0)\n",
    "  * e.g. LinearSVC(C=1.0, penalty=’l2’, loss=’squared_hinge’,...)\n",
    "* Instead of tweaking the parameters of the various components, it is possible to run an exhaustive search of the best parameters on a grid of possible values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.3.1 Grid search\n",
    "\n",
    "# import pipeline class\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# import GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# build a pipeline which does two steps all together:\n",
    "# (1) generate tfidf, and (2) train classifier\n",
    "# each step is named, i.e. \"tfidf\", \"clf\"\n",
    "\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', MultinomialNB())\n",
    "                   ])\n",
    "\n",
    "# set the range of parameters to be tuned\n",
    "# each parameter is defined as \n",
    "# <step name>__<parameter name in step>\n",
    "# e.g. min_df is a parameter of TfidfVectorizer()\n",
    "# \"tfidf\" is the name for TfidfVectorizer()\n",
    "# therefore, 'tfidf__min_df' is the parameter in grid search\n",
    "\n",
    "parameters = {'tfidf__min_df':[1, 2,5,10],\n",
    "              'tfidf__stop_words':[None,\"english\"],\n",
    "              'clf__alpha': [0.5,1.0,2.0],\n",
    "}\n",
    "\n",
    "# the metric used to select the best parameters\n",
    "metric =  \"f1_macro\"\n",
    "\n",
    "# GridSearch also uses cross validation\n",
    "gs_clf = GridSearchCV\\\n",
    "(text_clf, param_grid=parameters, \\\n",
    " scoring=metric, cv=5)\n",
    "\n",
    "# due to data volume and large parameter combinations\n",
    "# it may take long time to search for optimal parameter combination\n",
    "# you can use a subset of data to test\n",
    "gs_clf = gs_clf.fit(data[\"text\"], data[\"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha :  0.5\n",
      "tfidf__min_df :  2\n",
      "tfidf__stop_words :  english\n",
      "best f1 score: 0.9684663644232789\n",
      "\n",
      "\n",
      "{'clf__alpha': 0.5, 'tfidf__min_df': 2, 'tfidf__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "# gs_clf.best_params_ returns a dictionary \n",
    "# with parameter and its best value as an entry\n",
    "\n",
    "for param_name in gs_clf.best_params_:\n",
    "    print(param_name,\": \",gs_clf.best_params_[param_name])\n",
    "\n",
    "print(\"best f1 score:\", gs_clf.best_score_)\n",
    "print('\\n')\n",
    "print(gs_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3.3.2 Grid search\n",
    "# Modify Exercise 3.3 and Exercise 3.8 \n",
    "# to use the best parameters found\n",
    "# re-create the Multinominal NB classifier\n",
    "\n",
    "# also, check the dimension reduction of feature space by set min_df to 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-label classification\n",
    "- So far we only cover single-label classification, i.e. assign one class to each sample\n",
    "- Multilabel classification emerges as a challenging problem, where classes are not mutually exclusive \n",
    "  * music categorization \n",
    "  * semantic classification of images\n",
    "  * tagging\n",
    "- **One-Vs-the-Rest** Strategy (a.k.a **one-vs-all**)\n",
    "  * fitting one classifier per class. For each classifier, the class is fitted against all the other classes.\n",
    "  * for $n$ classes (labels), $n$ classifier is needed\n",
    "  * Advantage: good interpretability - Since each class is represented by one and only one classifier, it is possible to gain knowledge about the class by inspecting its corresponding classifier\n",
    "  * Disadvantage: \n",
    "     * many classifiers are created if there is a large number classes\n",
    "     * ignore the structure (or dependencies) of classes\n",
    "- **Class indication matrix** (or **one-hot encoding**): Encode categorical integer features using a one-hot aka one-of-K scheme. \n",
    "\n",
    "| Document    | Money       | Investment | Crime & Justice |\n",
    "| :-----------|:-----------:|:----------:|:--------------:|\n",
    "| 1           | 0           |      0     | 1              |\n",
    "| 2           | 1           |      1     | 0              |\n",
    "| 3           | 1           |      0     | 0              |\n",
    "| 4           | 0           |      1     | 1              |\n",
    "\n",
    "- **dataset**: Yahoo News Ranked Multilabel Learning dataset (http://research.yahoo.com)\n",
    "  - A subset is selected\n",
    "  - 4 classes, 6426 samples\n",
    "  \n",
    "- **Discussion**: can you apply Naive Bayes for multi-label classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'glenn neely reveals specific trading strategies for today s difficult marketstime is tue aug am et neowave founder discusses the three phases of every market and the best trading techniques for each vocus august in his new audio interview elliott wave expert and neowave founder glenn neely advises on specific trading strategies to survive the current challenging market based on his years of trading and forecasting experience neely describes the three phases of all markets and he provides advice on the best trading strategy to employ in the current market phase the three market phases are bottoming topping accumulation distribution and trending up or down the current phase of market action is most likely distribution neely explains we ve rallied significantly off s low and since january the market has been forming a top what type of strategies should traders use during this distribution phase the focus should be selling into strength as the market prepares for a top over the next few months in this period overbought and oversold indicators work the best look for overbought signals to sell into those overbought conditions with stops above the market get out of your short positions when the market is oversold most important focus on protecting capital select trades carefully and avoid big risky bets what s next after the stock market tops probably before december we ll start the final and most treacherous phase of this bear market which started at s high neely adds keep in mind a trending phase can produce the biggest profit potential at the lowest risk over the shortest period click to hear glenn neely s minute interview trading strategies for today s difficult markets in the next interview of glenn neely s stock market predictions series glenn neely will introduce his revolutionary neely river technology neely river focuses on how to manage trades in an unpredictable market environment how to enter positions move stops and exit positions without requiring any market perspective or forecasting expertise about glenn neely and neowave institute glenn neely who is internationally regarded as the premier elliott wave analyst founded the elliott wave institute in in neely published his advanced wave analysis process in his now classic book mastering elliott wave in neely changed the name of his research and advisory firm to neowave institute to differentiate his scientific wave analysis technology from orthodox subjective elliott wave analysis which is frequently nebulous inaccurate and constantly fluid what is elliott wave in the early ralph nelson elliott presented his theory of market behavior which quantifies each stage of an economic cycle into specific patterns of mass psychology glenn neely has devoted more than years to mastering and advancing the concepts of wave theory neely refined elliott wave theory to make it objective practical and consistently accurate producing his now famous neowave technology this precise step by step assessment of market structure leads to low risk high profit investing and trading orthodox elliott wave devoid of such technology and rules typically leaves the analyst with ambiguous interpretations seriously flawed results and dual directional forecasts today decades after r n elliott penned his original theory countless investors and traders trust neely s revolutionary step by step neowave approach to market analysis devotees of neowave institute and glenn neely are reaping the rewards of low risk high profit investing learn more about glenn neely and neowave institute at neowave institute inc patrice rhoades baum e mail information\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['money', 'investment-&-company-information', 'investment']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 4.1 Multi-label classification- Load data\n",
    "\n",
    "import json\n",
    "data=json.load(open(\"ydata.json\",\"r\"))\n",
    "\n",
    "docs,labels=zip(*data) # unzipped\n",
    "# *表示反向处理，即是从元组列表转换为分离的列表返回。\n",
    "\n",
    "# show sample examples\n",
    "docs[1]\n",
    "labels[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['.', 'a', 'c', 'd', 'e', 'g', 'h', 'i', 'l', 'm', 'n', 'o', 'p',\n",
       "       'r', 's', 't'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.' 'a' 'c' 'd' 'e' 'g' 'h' 'i' 'l' 'm' 'n' 'o' 'p' 'r' 's' 't']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 3, 3, 1, 3, 2, 3, 4, 2, 3, 1, 2, 1, 2, 4, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 4.2 One-hot coding of classes\n",
    "# reference : https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y=mlb.fit_transform(labels)\n",
    "# check size of indicator matrix\n",
    "Y.shape\n",
    "# check classes\n",
    "mlb.classes_ # all classes\n",
    "print(mlb.classes_)\n",
    "# check # of samples in each class\n",
    "np.sum(Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...lti_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=1))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Exercise 4.3 Multi-label classification- one vs. rest classifier\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# split dataset into train (70%) and test sets (30%)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\\\n",
    "                docs, Y, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "classifier = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=\"english\",\\\n",
    "                              min_df=2)),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC()))])\n",
    "\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1928, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1],\n",
       "       [0, 1, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1],\n",
       "       [0, 1, 1, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "                 crime-&-justice       0.98      0.98      0.98       764\n",
      "                      investment       0.91      0.97      0.94      1077\n",
      "investment-&-company-information       0.93      0.97      0.95      1032\n",
      "                           money       0.85      0.95      0.90       946\n",
      "\n",
      "                     avg / total       0.92      0.97      0.94      3819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4.4 Multi-label classification- Performance report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted = classifier.predict(X_test)\n",
    "\n",
    "predicted.shape\n",
    "predicted[0:2]\n",
    "Y_test[0:2]\n",
    "\n",
    "print(classification_report\\\n",
    "      (Y_test, predicted, target_names=mlb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Encoding and Decoding\n",
    "https://www.agiliq.com/blog/2014/11/character-encoding-and-unicode/\n",
    "https://www.agiliq.com/blog/2014/12/understanding-python-unicode-str-unicodeencodeerro/\n",
    "\n",
    "- Computers only work with binary (0 or 1). Any character needs to have **a binary representation** so computer can store it on disk or in the memory. However, there are various ways in which characters can be converted to binary.\n",
    "\n",
    "- **Unicode** provides standard code points for different characters. It can give code point for any character in any language.\n",
    "  - e.g. 'a' <-> integer 97, hexadecimal 61 (denoted as '\\u0061' or '\\x61')\n",
    "  - e.g. 'ä' <-> integer 228, hexadecimal E4\n",
    "  \n",
    "- Python 3 always stores **text strings as sequences of Unicode code points**.\n",
    "- However, in Python 2, text strings are stored as **binary representations** (i.e. bytes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Encoding\n",
    "- **Encoding** means the process of converting a string to a binary representation. \n",
    "  - There are diffent **coding schemes**  \n",
    "      - **ascii**: encodes 128 specified characters into seven-bit integers \n",
    "        - e.g. a <-> 01100001 \n",
    "      - **utf-8**: use one to four 8-bit bytes to encode 1,112,064 characters\n",
    "        - ä <-> 11000011 10100100, or '\\xc3\\xa4' (hexadecimal c3a4)    \n",
    "      - **latin-1**: map codepoints to byte values directly\n",
    "        - ä <-> '\\xe4' (hexadecimal 00E4)\n",
    "  - Each encoding, which confirms to Unicode, has **a one-to-one mapping between a Unicode code point and the binary representation of codepoint**.\n",
    "  \n",
    "- Function **encode()**: convert a Unicode string to a binary representation according to an encoding scheme\n",
    "- **UnicodeEncodeError**: Encode a unicode string which is not in the scope of encoding scheme\n",
    "  - e.g. try to encode u'\\u00E4' with ascii scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xc3\\xa4'\n",
      "ä\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'utf-8'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise 5.1.1\n",
    "\n",
    "s =  u'\\xE4'  # set unicode string. Note prefix u\n",
    "\n",
    "# encode into binary\n",
    "utf_s=s.encode(\"utf-8\")\n",
    "print(utf_s)\n",
    "\n",
    "# During printing or writing files, \n",
    "# since Python can only print ‘str’ (binary bytes)\n",
    "# it converts the ‘unicode’ into ‘str’ \n",
    "# using default system encoding\n",
    "print(s)\n",
    "\n",
    "# to check default encoding scheme\n",
    "import sys\n",
    "sys.getdefaultencoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character '\\xe4' in position 18: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-05e69baa0370>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# However, you cannot encode s using ascii, why?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mutf_s\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ascii\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutf_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character '\\xe4' in position 18: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "# Exercise 5.1.2 UnicodeEncodeError\n",
    "\n",
    "s =  u'this is a strange \\xE4 character'\n",
    "\n",
    "# However, you cannot encode s using ascii, why?\n",
    "utf_s=s.encode(\"ascii\")\n",
    "print(utf_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Decoding\n",
    "- **decoding**: the process of converting an encoded binary representation into Unicode codepoint.\n",
    "\n",
    "- Function **decode()**: convert a binary string to a Unicode string according to an encoding scheme\n",
    "- **UnicodeDecodeError**: decode a binary string which is not in the scope of encoding scheme\n",
    "  - e.g. try to decode b'\\u00E4' with ascii scheme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.2.1. Decoding with UTF-8\n",
    "\n",
    "# A binary string (i.e. byte) has a prefix \"b\"\n",
    "s =  b'\\xc3\\xa4'\n",
    "utf_s = s.decode('utf-8') # convert to Unicode using UTf-8. The result is u'\\xE4'\n",
    "\n",
    "print(utf_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xc3 in position 0: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-ed12b9ba314c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;34mb'\\xc3\\xa4'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mutf_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# convert to Unicode using ascii\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutf_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xc3 in position 0: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "# Exercise 5.2.2. UnicodeDecodeError\n",
    "\n",
    "s =  b'\\xc3\\xa4'\n",
    "utf_s = s.decode('ascii') # convert to Unicode using ascii\n",
    "print(utf_s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strange  text\n",
      "strange �� text\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5.2.2. Encoding/decoding exception handling\n",
    "# 'strict', 'ignore', and 'replace' \n",
    "\n",
    "s =  b'strange \\xc3\\xa4 text'\n",
    "utf_s = s.decode('ascii', errors='ignore') # convert to Unicode, which is u'\\xE4'\n",
    "print(utf_s)\n",
    "\n",
    "utf_s = s.decode('ascii', errors='replace') # convert to Unicode, which is u'\\xE4'\n",
    "print(utf_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

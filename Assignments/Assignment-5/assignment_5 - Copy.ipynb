{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Kai Zhang\n",
    "# Stevens Intitute of Technology\n",
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=pd.read_csv(\"news_train.csv\",header=0)\n",
    "#data.head()\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Kai Zhang\n",
    "# Stevens Institute of Technology\n",
    "\n",
    "# import method for split train/test data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import method to calculate metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import svm\n",
    "# import pipeline class\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# import GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def classify (training_file, testing_file):\n",
    "    data = pd.read_csv(training_file,header=0)\n",
    "    text_clf = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', svm.LinearSVC())\n",
    "                   ])\n",
    "    parameters = {'tfidf__min_df':[1,2,5],\n",
    "              'tfidf__stop_words':[None,\"english\"],\n",
    "              'clf__C': [0.5,1,5]\n",
    "    }\n",
    "    # the metric used to select the best parameters\n",
    "    metric =  \"f1_macro\"\n",
    "\n",
    "    # GridSearch also uses cross validation\n",
    "    gs_clf = GridSearchCV\\\n",
    "    (text_clf, param_grid=parameters, \\\n",
    "     scoring=metric, cv=6)\n",
    "    \n",
    "    gs_clf = gs_clf.fit(data[\"text\"], data[\"label\"])\n",
    "    print(\"GridSearch results:\")\n",
    "    for param_name in gs_clf.best_params_:\n",
    "        print(param_name,\": \",gs_clf.best_params_[param_name])\n",
    "    \n",
    "    print(\"Using Grid Search, the best f1 score:\\n\", gs_clf.best_score_)\n",
    "    \n",
    "    # Using the best parameter values, train a linear support vector machine classifier with /\n",
    "    # all samples in news_train.csv\n",
    "    \n",
    "    # initialize the TfidfVectorizer \n",
    "\n",
    "    tfidf_vect = TfidfVectorizer(min_df=gs_clf.best_params_['tfidf__min_df'],stop_words=gs_clf.best_params_['tfidf__stop_words']) \n",
    "    \n",
    "    # generate tfidf matrix\n",
    "    dtm= tfidf_vect.fit_transform(data[\"text\"])\n",
    "    \n",
    "    # split dataset into train (100%) and test sets (0%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "                dtm, data[\"label\"], test_size=0.0, random_state=0)\n",
    "    \n",
    "    # train a SVM model using the train data\n",
    "    clf = svm.LinearSVC(C=gs_clf.best_params_['clf__C']).fit(X_train, y_train)\n",
    "    \n",
    "    # predict the news group for the test dataset\n",
    "    data_test = pd.read_csv(testing_file,header=0)\n",
    "    dtm_test= tfidf_vect.transform(data_test[\"text\"])\n",
    "    predicted=clf.predict(dtm_test)\n",
    "\n",
    "    # get the list of unique labels\n",
    "    labels=sorted(data_test[\"label\"].unique())\n",
    "    \n",
    "    # to get all performance metrics\n",
    "    print('\\n')\n",
    "    print(\"Show all performance metrics\")\n",
    "    print(classification_report\\\n",
    "      (data_test[\"label\"], predicted, target_names=labels))\n",
    "\n",
    "    # compare\n",
    "    print('\\n')\n",
    "    print(\"Comments:\")\n",
    "    print(\"We have known that the best f1 score from grid search is 0.8753..., however \\\n",
    "    f1-macro score obtained from the test dataset is 0.90 which is greater than previous one. Therefore\\\n",
    "    the model is overfitted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=pd.read_csv(\"news_train.csv\",header=0)\n",
    "#length=len(data)\n",
    "#for i in range(0,length,300):\n",
    "#    if i%300==0:\n",
    "#        a=pd.read_csv(\"news_train.csv\",header=0,nrows=i)\n",
    "        #print(len(a))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-88-8aae59292c05>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-88-8aae59292c05>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    tfidf_vect = TfidfVectorizer(stop_words=\"english\")\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def impact_of_sample_size(train_file, test_file):\n",
    "    data=pd.read_csv(train_file,header=0)\n",
    "    length=len(data)\n",
    "    # store the information about evaluation on model\n",
    "    size=[]\n",
    "    precision_Bayes=[]\n",
    "    recall_Bayes=[]\n",
    "    precision_SVM=[]\n",
    "    recall_SVM=[]\n",
    "    for i in range(0,length,300):\n",
    "        if i%300==0 and i!=0:\n",
    "            size.append(i)\n",
    "            train=pd.read_csv(train_file,header=0,nrows=i)\n",
    "            round_process(train,test_file)\n",
    "    round_process(train_file,test_file)\n",
    "    size.append(length)\n",
    "    \n",
    "    #draw a line chart\n",
    "    plt.plot(size,precision_Bayes,'s-',color = 'r',label=\"multinomial Naive Bayes\")\n",
    "    plt.plot(size,precision_SVM,'o-',color = 'b',label=\"linear support vector machine\")\n",
    "    xlabel('Sample Size')\n",
    "    ylabel('Precision')\n",
    "    title('the relationship between sample size and precision')\n",
    "    grid(True)\n",
    "    show()\n",
    "    \n",
    "    plt.plot(size,recall_Bayes,'s-',color = 'r',label=\"multinomial Naive Bayes\")\n",
    "    plt.plot(size,recall_SVM,'o-',color = 'b',label=\"linear support vector machine\")\n",
    "    xlabel('Sample Size')\n",
    "    ylabel('Recall')\n",
    "    title('the relationship between sample size and recall')\n",
    "    grid(True)\n",
    "    show()\n",
    "            \n",
    "def round_process(train, test):\n",
    "    # initialize the TfidfVectorizer with stop words removed\n",
    "    tfidf_vect = TfidfVectorizer(stop_words=\"english\")\n",
    "    # generate tfidf matrix\n",
    "    dtm= tfidf_vect.fit_transform(train[\"text\"])\n",
    "    # split dataset into train (100%) and test sets (0%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "                dtm, train[\"label\"], test_size=0.0, random_state=0)\n",
    "    \n",
    "    # train a multinomial naive Bayes model using the training data\n",
    "    clf = MultinomialNB().fit(X_train, y_train)\n",
    "    # predict the news group for the test dataset\n",
    "    data_test = pd.read_csv(test,header=0)\n",
    "    dtm_test= tfidf_vect.transform(data_test[\"text\"])\n",
    "    # get the list of unique labels\n",
    "    labels=sorted(data_test[\"label\"].unique())\n",
    "    predicted=clf.predict(dtm_test)\n",
    "    # calculate performance metrics. \n",
    "    # Support is the number of occurrences of each label\n",
    "    precision, recall, fscore, support=\\\n",
    "         precision_recall_fscore_support(\\\n",
    "         data_test[\"label\"], predicted, labels=labels,average=\"macro\")\n",
    "    precision_Bayes.append(precision)\n",
    "    recall_Bayes.append(recall)\n",
    "    \n",
    "    # train a SVM model\n",
    "    clf = svm.LinearSVC().fit(X_train, y_train)\n",
    "    # predict the news group for the test dataset\n",
    "    predicted=clf.predict(dtm_test)\n",
    "    # calculate performance metrics. \n",
    "    # Support is the number of occurrences of each label\n",
    "    precision, recall, fscore, support=\\\n",
    "         precision_recall_fscore_support(\\\n",
    "         data_test[\"label\"], predicted, labels=labels,average=\"macro\")\n",
    "    precision_SVM.append(precision)\n",
    "    recall_SVM.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__C :  0.5\n",
      "tfidf__min_df :  1\n",
      "tfidf__stop_words :  english\n",
      "Using Grid Search, the best f1 score:\n",
      " 0.8753227874289731\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Business       0.90      0.85      0.87       136\n",
      "   Sci/Tech       0.87      0.89      0.88       130\n",
      "     Sports       0.96      0.98      0.97       118\n",
      "      World       0.89      0.91      0.90       116\n",
      "\n",
      "avg / total       0.90      0.90      0.90       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "# Test Q1 Classification\n",
    "    print(\"Test Q1: Classification\")\n",
    "    classify (\"news_train.csv\",\"news_test.csv\")\n",
    "    \n",
    "# Test Q2 \n",
    "    print(\"Test Q2: Show the impact of sample size on classifier performance\")\n",
    "    impact_of_sample_size(train_file, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-a488d9b43708>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprecision_SVM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrecall_SVM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mimpact_of_sample_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"news_train.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"news_test.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-86-a6a55b832fa6>\u001b[0m in \u001b[0;36mimpact_of_sample_size\u001b[1;34m(train_file, test_file)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mround_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mround_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0msize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-86-a6a55b832fa6>\u001b[0m in \u001b[0;36mround_process\u001b[1;34m(train, test)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mtfidf_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"english\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# generate tfidf matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mdtm\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtfidf_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[1;31m# split dataset into train (100%) and test sets (0%)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     X_train, X_test, y_train, y_test = train_test_split(\\\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "size=[]\n",
    "precision_Bayes=[]\n",
    "recall_Bayes=[]\n",
    "precision_SVM=[]\n",
    "recall_SVM=[]\n",
    "impact_of_sample_size(\"news_train.csv\",\"news_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Assignment 2</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Define a function to analyze a numpy array\n",
    " - Assume we have an array which contains term frequency of each document. Where each row is a document, each column is a word, and the value denotes the frequency of the word in the document. Define a function named \"analyze_tf\" which:\n",
    "      * has two input parameters: \n",
    "        * a rank 2 input array\n",
    "        * a parameter \"binary\" with a default value set to False\n",
    "      * does the following steps in sequence:\n",
    "        1. if \"binary\" is True, binarizes the input array, i.e. if a value is greater than 1, change it to 1. \n",
    "        2. normalizes the frequency of each word as: word frequency divided by the length of the document (i.e. sum of each row). Save the result as an array named **tf** (i.e. term frequency). The sum of each row of tf should be 1.\n",
    "        3. calculates the document frequency (**df**) of each word, i.e. how many documents contain a specific word\n",
    "        4. calculate the inverse document frequency (**idf**) of each word as ** N/df ** (df divided by N) where N is the number of documents\n",
    "        5. calculates **tf_idf** array as: **tf * log (idf)** (tf multiply the log (base e) of idf ). The reason is, if a word appears in most documents, it does not have the discriminative power and often is called a \"stop\" word. The inverse of df can downgrade the weight of such words.\n",
    "      * returns the tf_idf array.\n",
    " - Note, for all the steps, ** do not use any loop**. Just use array functions and broadcasting for high performance computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Define a function to analyze car dataset using pandas\n",
    " - Define a function named \"analyze_cars\" to do the follows:\n",
    "   * Take a csv file path string as an input. Assume the csv file is in the format of the provided sample file.\n",
    "   * Read the csv file as a dataframe with the first row as column names\n",
    "   * Find cars with top 3 mpg among those of origin = 1. Print the names (i.e. \"car\" column) and mpg of these three cars.\n",
    "   * Create a new column called \"brand\" to store the brand name as the first word in \"car\" column (hint: use \"apply\" function)\n",
    "   * Show the mean, min, and max mpg values for each of these brands: \"ford\", \"buick\" and \"honda\"\n",
    "   * Create a cross tab to show the average mpg of each brand and each origin value. Use \"brand\" as row index and \"origin\" as column index. \n",
    " - This function does not have any return. Just print out the result of each calculation step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 (Bonus). More sophisticated analyze_tf function\n",
    " - Assume we have an array which contains term frequency of each document. Where each row is a document, each column is a word, and the value denotes the frequency of the word in the document. Define a function named \"advanced_analyze_tf\" which:\n",
    "      * has three input parameters: \n",
    "        * a rank 2 input array\n",
    "        * a parameter \"min_df\" (minimum document frequency) with a default value set to 0 \n",
    "        * a parameter \"max_words\" (maximum number of words) with a default value set None\n",
    "      * process the input array as follows in sequence:\n",
    "        1. if \"min_df\">0, remove words with document frequency (df) less than \"min_df\", i.e. the corresponding columns are removed \n",
    "        2. if \"max_words\"> 0 and \"max_words\" < the total number of columns (M), only words with top \"max_words\" frequency (df) are kept. M - \"max_words\" columns are removed from the array\n",
    "      * call the analyze_tf function in Q1 using the resulting array to get an tf_idf array\n",
    "      * returns tf_idf and the original indexes of remaining words.\n",
    " - Note, for all the steps, ** do not use any loop**. Just use array functions and broadcasting for high performance computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Guideline##\n",
    "- Following the solution template provided below. Use __main__ block to test your functions\n",
    "- Save your code into a python file (e.g. assign2.py) that can be run in a python 3 environment. In Jupyter Notebook, you can export notebook as .py file in menu \"File->Download as\".\n",
    "- Make sure you have all import statements. To test your code, open a command window in your current python working folder, type \"python assign1.py\" to see if it can run successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Structure of your solution to Assignment 1 \n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def car_analysis(filepath):\n",
    "    # add your code\n",
    "    \n",
    "def analyze_tf(arr, binary=False):\n",
    "    \n",
    "    tf_idf=None\n",
    "    \n",
    "    # add your code\n",
    "    \n",
    "    return tf_idf\n",
    "\n",
    "def advanced_analyze_tf(arr, min_df=0, max_words=None):\n",
    "    \n",
    "    tf_idf=None\n",
    "    \n",
    "    # add your code\n",
    "    \n",
    "    return tf_idf\n",
    "\n",
    "# best practice to test your class\n",
    "# if your script is exported as a module,\n",
    "# the following part is ignored\n",
    "# this is equivalent to main() in Java\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    # Test Question 1\n",
    "    arr=np.array([[0,1,0,2,0,1],[1,0,1,1,2,0],[0,0,2,0,0,1]])\n",
    "    \n",
    "    print(arr, binary=False)\n",
    "    # You should get \n",
    "    # [[0.         0.27465307 0.         0.20273255 0.         0.10136628]\n",
    "     # [0.21972246 0.         0.08109302 0.08109302 0.43944492 0.        ]\n",
    "      #[0.         0.         0.27031007 0.         0.         0.13515504]]\n",
    "   \n",
    "    print(arr, binary=True)\n",
    "    # You should get\n",
    "     #[[0.         0.3662041  0.         0.13515504 0.         0.13515504]\n",
    "     # [0.27465307 0.         0.10136628 0.10136628 0.27465307 0.        ]\n",
    "     # [0.         0.         0.20273255 0.         0.         0.20273255]]\n",
    "    \n",
    "    # test question 2\n",
    "    \n",
    "    car_analysis('../../dataset/cars.csv')\n",
    "    \n",
    "    # test question 3\n",
    "    \n",
    "    tf_idf, selected_words=advanced_analyze_tf(arr, min_df=2, max_words=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
